library(sjstats)
library(moments)
?cv
sjstats::cv(pesos) ##Coeficiente de variación
sd(pesos) ###Desviación estándar
sd(pesos)^2 ###Varianza
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",
sheet = "Ejemplo")
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",
sheet = "Ejemplo")
View(Ponderada)
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",     sheet = "Ejemplo")
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",sheet = "Ejemplo")
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",
sheet = "Ejemplo")
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",
+     sheet = "Ejemplo")
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx", sheet = "Ejemplo")
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",
sheet = "Ejemplo")
library(readxl)
Ponderada <- read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",sheet = "Ejemplo")
library(readxl)
read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",sheet = "Ejemplo")
read_excel("Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva/Ponderada.xlsx",sheet = "Ejemplo")
shiny::runApp('Documents/GitHub/Shiny/Estadistica para Geografos/Estimacion_Puntual_IC')
runApp('Documents/GitHub/Shiny/Estadistica para Geografos/Estimacion_Puntual_IC')
rsconnect::setAccountInfo(name='sergio-alejandro-calderon-villanueva', token='EC8D10D6C986A817442AB2D9691CFD18', secret='5sIldC0Qnp5pBwOBUshqh/Y8d0U023K2qa1DdPvN')
runApp('Documents/GitHub/Shiny/Estadistica para Geografos/Estimacion_Puntual_IC')
runApp('Documents/GitHub/Shiny/Estadistica para Geografos/Estimacion_Puntual_IC')
library(OneTwoSamples)
library(OneTwoSamples)
install.packages("EnvStats")
library(EnvStats)
library(EnvStats)
Pesos_Alturas_Diametros <- read_excel("Pesos_Alturas_Diametros.xlsx")
setwd("/Users/sergiocalderon/Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva")
Pesos_Alturas_Diametros <- read_excel("Pesos_Alturas_Diametros.xlsx")
library(readxl)
library(EnvStats)
Pesos_Alturas_Diametros <- read_excel("Pesos_Alturas_Diametros.xlsx")
Pesos_Alturas_Diametros <- read_excel("Pesos_Alturas_Diametros.xlsx")
hist(Pesos_Alturas_Diametros$Pesos)
boxplot(Pesos_Alturas_Diametros$Pesos)
mean(Pesos_Alturas_Diametros$Pesos)
sd(Pesos_Alturas_Diametros$Pesos)
qqnorm(Pesos_Alturas_Diametros$Pesos, pch = 1, frame = FALSE)
qqline(Pesos_Alturas_Diametros$Pesos, col = "steelblue", lwd = 2)
library(car)
library(Pesos_Alturas_Diametros$Pesos)
car::qqPlot(Pesos_Alturas_Diametros$Pesos)
EnvStats::qqPlot(Pesos_Alturas_Diametros$Pesos, add.line = TRUE)
?interval_estimate1
OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=-1,alpha=0.05)
library(OneTwoSamples)
t.test(Pesos_Alturas_Diametros$Pesos,var.equal =FALSE,conf.level = 0.95 ). ##Varianza conocida###
library(OneTwoSamples)
t.test(Pesos_Alturas_Diametros$Pesos,var.equal =FALSE,conf.level = 0.95 ) ##Varianza conocida###
OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=-1,alpha=0.05)
?interval_estimate3
?interval_estimate2
?interval_estimate4
?interval_estimate3
salida_IC<-OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=-1,alpha=0.05)###sigma=-1 quiere decir que la varianza es desconocida.
salida_IC$a  #límite inferior.
salida_IC$b  #Límite superior.
library(OneTwoSamples)
t.test(Pesos_Alturas_Diametros$Pesos,var.equal =FALSE,conf.level = 0.95 ) ##Varianza conocida###
salida_IC<-OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=-1,alpha=0.05)###sigma=-1 quiere decir que la varianza es desconocida.
salida_IC$a  #límite inferior.
salida_IC$b  #Límite superior.
salida_IC_var_cono<-OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=3,alpha=0.05)
salida_IC_var_cono<-OneTwoSamples::interval_estimate1(Pesos_Alturas_Diametros$Pesos,sigma=3,alpha=0.05)
salida_IC_var_cono$a
salida_IC_var_cono$b
salida_IC_var_cono$df
?interval_estimate2
?interval_estimate3
?interval_estimate4
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=-1,side=,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=1,side=,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=0,side=,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=-1,side=-1,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=-1,side=1,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=-1,side=0,alpha=0.05)
interval_estimate4(Pesos_Alturas_Diametros$Pesos,sigma=-1,side=-1,alpha=0.05)
0.5^2*1.96^2/(0.05^2)
0.5^2*1.96^2/(0.10^2)
4/30
300*0.13*0.77/(299*0.05^/1.96^2+0.13*0.77)
300*0.13*0.77/(299*0.05^2/1.96^2+0.13*0.77)
10*0.13*0.77/(9*0.05^2/1.96^2+0.13*0.77)
?interval_estimate1
?interval_estimate2
?interval_estimate3
?interval_estimate4
?interval_estimate3
xbar=mean(Pesos_Alturas_Diametros$Pesos)
desv.est=sd(Pesos_Alturas_Diametros$Pesos)
n=length(Pesos_Alturas_Diametros$Pesos)
xbar
desv.est
n
alpha=0.01
cuantilt=qt(1-alpha/2,n-1)
cuantilz=qnorm(1-alpha/2,0,1)
cuantilz
cuantilt
linf=xbar-cuantilt*(desv.est/sqrt(n))
lsup=xbar+cuantilt*(desv.est/sqrt(n))
linf=xbar-cuantilz*(desv.est/sqrt(n))
lsup=xbar+cuantilz*(desv.est/sqrt(n))
alpha=0.05
quantilchisq1=qchisq(1-alpha/2,n)
quantilchisq2=qchisq(alpha/2,n)
linfvar=(n-1)*desv.est^2/quantilchisq1
linfsup=(n-1)*desv.est^2/quantilchisq2
linfvar
linfsup
desv.est=sd(Pesos_Alturas_Diametros$Pesos)
n=length(Pesos_Alturas_Diametros$Pesos)
alpha=0.05
quantilchisq1=qchisq(1-alpha/2,n)
quantilchisq2=qchisq(alpha/2,n)
linfvar=(n-1)*desv.est^2/quantilchisq1
linfsup=(n-1)*desv.est^2/quantilchisq2
linfvar
linfsup
interval_var1(Pesos_Alturas_Diametros$Pesos,mu=Inf,alpha=0.05) ##mu=Inf indica que la media poblacional mu es desconocida.
desv.est=sd(Pesos_Alturas_Diametros$Pesos)
n=length(Pesos_Alturas_Diametros$Pesos)
alpha=0.05
quantilchisq1=qchisq(1-alpha/2,n-1)
quantilchisq2=qchisq(alpha/2,n-1)
linfvar=(n-1)*desv.est^2/quantilchisq1
linfsup=(n-1)*desv.est^2/quantilchisq2
linfvar
linfsup
interval_var1(Pesos_Alturas_Diametros$Pesos,mu=Inf,alpha=0.05) ##mu=Inf indica que la media poblacional mu es desconocida.
data("AirPassengers")
lAirPass=log(lAirPass)
lAirPass=log(AirPassengers)
h=3
lAirPass ###Vamos a trabajar con la serie en escala logarítmica
#HWAP=stats::HoltWinters(lAirPass,seasonal="additive")
### Definición o creación del conjunto de entrenamiento y de Prueba##
lserie=length(lAirPass)
ntrain=trunc(length(lAirPass)*0.85) ##% del datos en el conjunto de entrenamiento es del 85%.
ntrain
time(lAirPass)
time(lAirPass)[ntrain]###Me entrega la ultima fecha de la posición ntrain
train=window(lAirPass,end=time(lAirPass)[ntrain])
test=window(lAirPass,start=time(lAirPass)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest])
for(j in 2:h){
verval=cbind(verval,c(test[j:ntest],rep(NA,j-1)))
} # aqui se esta haciendo la ventana de rolling
verval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA)) # verdaderos valores de ventana rolling con tres pasos adelante
####Ajuste del modelo con los datos de entrenamiento
HWAP_train=stats::HoltWinters(train,seasonal="additive")
HWAP_train$alpha
HWAP_train$beta
HWAP_train$gamma
###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores.
# por ejemplo como sigue:
require(utils)
suav_inputs=cbind(seq(0.001,0.999,0.3),seq(0.001,0.999,0.3),seq(0.001,0.999,0.3))# se hace una grilla de valores para los parametros
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma) ##Grilla de Valores, posibles combinaciones de los paramtros
EDM2 <- matrix(0, nrow = nrow(grilla_suav), ncol = h)
for(j in 1:nrow(grilla_suav)){
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
alpha <- as.numeric(grilla_suav[5,][1])
beta  <- as.numeric(grilla_suav[j,][2])
gamma <- as.numeric(grilla_suav[j,][3])
for(i in 1:(ntest))  # for adicional de grilla en grilla y guradando los errores cuadraticos medios
{ #
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12) # donde esta la ventana agregando una por una
# print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=alpha,beta=beta,gamma=gamma) # ajuste con los hiper fijos
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean) # prediccion h=1, y luego la media
# errores de prediccion por ventana
errores_pred =verval - fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
EDM2[j,] = apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE)
}
RECM=sqrt(EDM2) ##Se le saca raíz
}
RECM # Cada fila es el error cuadrático medio de cada posible combinación
error_total_por_combinacion <- apply(RECM, 1, sum) # se suma el error total de cada combinación
mejor_combinacion <- which.min(error_total_por_combinacion) #esta es la combinación que minimza el error cuadrático medio total
print(paste("el valor de alpha sugerido es alpha =", grilla_suav[mejor_combinacion,][1]))
print(paste("el valor de alpha sugerido es beta =", grilla_suav[mejor_combinacion,][2]))
print(paste("el valor de alpha sugerido es gamma =", grilla_suav[mejor_combinacion,][3]))
# Librerias
library(tsibble)
library(forecast)
# Datos
data("AirPassengers")
lAirPass=log(AirPassengers)
ntrain=trunc(length(lAirPass)*0.85)
train=window(lAirPass,end=time(lAirPass)[ntrain])
test=window(lAirPass,start=time(lAirPass)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma) ##Grilla de Valores
h=3
ntrain=length(train)
ntest=length(test)
verval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA))
fchstepahe=matrix(0,nrow=ntest,ncol=h)
RECM=matrix(0,nrow=nrow(grilla_suav),ncol=h)
for (i in 1:nrow(grilla_suav))
{
for(j in 1:(ntest))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(j-1)/12)
refit=stats::HoltWinters(x,seasonal="additive",alpha = grilla_suav[i,1],
beta = grilla_suav[i,2], gamma = grilla_suav[i,3])
fchstepahe[j,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
errores_pred = verval - fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM).
RECM[i,]=sqrt(ECM) ##Se le saca raíz
}
# Mejore hiperparametros
# Un paso adelante
which.min(RECM[,1])
grilla_suav[which.min(RECM[,1]),]
# Dos pasos adelante
which.min(RECM[,2])
grilla_suav[which.min(RECM[,2]),]
# Tres pasos adelante
which.min(RECM[,3])
grilla_suav[which.min(RECM[,3]),]
knitr::opts_chunk$set(echo = TRUE)
h=3
lAirPass ###Vamos a trabajar con la serie en escala logarítmica
#HWAP=stats::HoltWinters(lAirPass,seasonal="additive")
### Definición o creación del conjunto de entrenamiento y de Prueba##
lserie=length(lAirPass)
ntrain=trunc(length(lAirPass)*0.85) ##% del datos en el conjunto de entrenamiento es del 85%.
ntrain
time(lAirPass)
time(lAirPass)[ntrain]###Me entrega la ultima fecha de la posición ntrain
train=window(lAirPass,end=time(lAirPass)[ntrain])
test=window(lAirPass,start=time(lAirPass)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest])
for(j in 2:h){
verval=cbind(verval,c(test[j:ntest],rep(NA,j-1)))
}
verval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA))
####Ajuste del modelo con los datos de entrenamiento
HWAP_train=stats::HoltWinters(train,seasonal="additive")
HWAP_train$alpha
HWAP_train$beta
HWAP_train$gamma
###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores.
# por ejemplo como sigue:
require(utils)
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma) ##Grilla de Valores
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas)
for(i in 1:(ntest))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=HWAP_train$alpha,beta=HWAP_train$beta,gamma=HWAP_train$gamma)
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
fchstepahe
errores_pred=verval -fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM).
RECM=sqrt(ECM) ##Se le saca raíz
RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente.
library(forecast)
library(greybox)
library(binom)
?binom.confint
setwd("/Users/sergiocalderon/Documents/GitHub/EstadisticaParaGeografos/EstadisticaParaGeografosUN/Estadistica_Descriptiva")
list.files()
encuesta_hog<-read_excel("EncHog2022.xlsx")
library(readxl)
EncHog2022 <- read_excel("EncHog2022.xlsx",
col_types = c("text", "text", "numeric",
"numeric", "text", "numeric", "numeric",
"numeric"))
View(EncHog2022)
encuesta_hog<-EncHog2022 <- read_excel("EncHog2022.xlsx",
col_types = c("text", "text", "numeric",
"numeric", "text", "numeric", "numeric",
"numeric"))
EncHog2022$Contrato_lab
?binom.confint
binom.confint(x = c(2, 4), n = 100, tol = 1e-8)
sum(EncHog2022$Contrato_lab=="1")
length(EncHog2022$Contrato_lab)
sum(EncHog2022$Contrato_lab=="2")
sum(EncHog2022$Contrato_lab=="2")+sum(EncHog2022$Contrato_lab=="2")
sum(EncHog2022$Contrato_lab=="2")+sum(EncHog2022$Contrato_lab=="1")
binom.confint(sum(EncHog2022$Contrato_lab=="1"), length(EncHog2022$Contrato_lab))
binom.confint(c(sum(EncHog2022$Contrato_lab=="1"),sum(EncHog2022$Contrato_lab=="2")), length(EncHog2022$Contrato_lab))### para la proporción de éxitos y fracasos, es decir, la proporción de personas que tienen contrato y las que no tiene contrato.
# Rolling 1
# Carga de datos
data("AirPassengers")
lAirPass=log(AirPassengers) # Serie log
h=3 # Ventana
### Definición o creación del conjunto de entrenamiento y de Prueba##
lserie=length(lAirPass)
ntrain=trunc(length(lAirPass)*0.85) ##% del datos en el conjunto de entrenamiento es del 85%.
ntrain
time(lAirPass)
time(lAirPass)[ntrain]###Me entrega la ultima fecha de la posición ntrain
train=window(lAirPass,end=time(lAirPass)[ntrain])
test=window(lAirPass,start=time(lAirPass)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest])
for(j in 2:h){
verval=cbind(verval,c(test[j:ntest],rep(NA,j-1)))
}
verval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA))
####Ajuste del modelo con los datos de entrenamiento
HWAP_train=stats::HoltWinters(train,seasonal="additive")
HWAP_train$alpha
HWAP_train$beta
HWAP_train$gamma
# Creación grilla
require(utils)
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma) ##Grilla de Valores
# Implementación grilla
for(i in 1:(ntest))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=HWAP_train$alpha,beta=HWAP_train$beta,gamma=HWAP_train$gamma)
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
ecm_grilla=matrix(99,nrow=nrow(grilla_suav),ncol=3)
recm <- ecm_grilla
# Implementación grilla
for(i in 1:(nrow(grilla_suav)))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3])
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
ecm_grilla[i,]=apply((verval -fchstepahe)^2,MARGIN = 2,mean,na.rm=TRUE) ##Observación: debo devolver los pronósticos
}
# Implementación grilla
for(i in 1:(nrow(grilla_suav)))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=grilla_suav[i,1],beta=grilla_suav[i,2],gamma=grilla_suav[i,3])
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
ecm_grilla[i,]=apply((verval -fchstepahe)^2,MARGIN = 2,mean,na.rm=TRUE) ##Observación: debo devolver los pronósticos
}
# Implementación grilla
for(j in 1:(nrow(grilla_suav)))
{
for(i in 1:(ntest))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
print(length(x))
refit=stats::HoltWinters(x,seasonal="additive",alpha=grilla_suav[j,1],beta=grilla_suav[j,2],gamma=grilla_suav[j,3])
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
ecm_grilla[j,]=apply((verval -fchstepahe)^2,MARGIN = 2,mean,na.rm=TRUE) ##Observación: debo devolver los pronósticos
}
recm_grilla <- sqrt-(ecm_grilla)
recm_grilla <- sqrt(ecm_grilla)
min_pasos=c(min(ecm_grilla[,1]),min(ecm_grilla[,2]),min(ecm_grilla[,3]))
posiciones_hiperpar <- c(which(ecm_grilla[,1]==min_pasos[1]),which(ecm_grilla[,2]==min_pasos[2]),which(ecm_grilla[,3]==min_pasos[3]))
respuesta <- rbind(grilla_suav[posiciones_hiperpar[1],],grilla_suav[posiciones_hiperpar[2],],grilla_suav[posiciones_hiperpar[3],])
rownames(respuesta) <- c("un paso","dos pasos","tres pasos")
errores_pred=verval -fchstepahe ##Observación: debo devolver los pronósticos
errores_pred
respuesta
data("AirPassengers")
plot(AirPassengers)
#####Transformación Box-Cox
#library(FitAR)
library(forecast)
forecast::BoxCox.lambda(AirPassengers, method = "guerrero", lower = 0, upper = 2)
#air.arima<-arima(AirPassengers, c(0,1,1), seasonal=list(order=c(0,1,1), period=12))
#FitAR::BoxCox(air.arima)
lAirPass=log(AirPassengers)
par(mfrow=c(2,1))
plot(AirPassengers)
plot(lAirPass)
h=3
lAirPass ###Vamos a trabajar con la serie en escala logarítmica
#HWAP=stats::HoltWinters(lAirPass,seasonal="additive")
### Definición o creación del conjunto de entrenamiento y de Prueba##
lserie=length(lAirPass)
ntrain=trunc(length(lAirPass)*0.85) ##% del datos en el conjunto de entrenamiento es del 85%.
ntrain
time(lAirPass)
time(lAirPass)[ntrain]###Me entrega la ultima fecha de la posición ntrain
train=window(lAirPass,end=time(lAirPass)[ntrain])
test=window(lAirPass,start=time(lAirPass)[ntrain]+1/12)##1/12 porque es la fracción que corresponde a un mes
length(train)
ntest=length(test)
ntest ##Me define el valor de origins, o de ventanas de rolling.
lserie ### Comparar los valores
fchstepahe=matrix(0,nrow=ntest,ncol=h) ##Crea una Columna para los h-pasos adelante
### verval contiene los verdaderos valores de la serie en el conjunto de prueba con los que se compararán los pronósticos.
verval=cbind(test[1:ntest])
for(j in 2:h){
verval=cbind(verval,c(test[j:ntest],rep(NA,j-1)))
}
verval=cbind(test[1:ntest],c(test[2:ntest],NA),c(test[3:ntest],NA,NA))
###Observación: Note que que esos son las estimaciones de los parámetros de suavizamiento. Se puede también hacer una grilla de valores para explorar si hay unos valores mejores.
# por ejemplo como sigue:
require(utils)
#suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
suav_inputs=cbind(seq(0.001,0.999,0.1),seq(0.001,0.999,0.1),seq(0.001,0.999,0.1))
colnames(suav_inputs)<-c("alpha","beta","gamma")
suav_inputs_tbl=tibble::as_tibble(suav_inputs)
grilla_suav=expand.grid(alpha=suav_inputs_tbl$alpha,beta=suav_inputs_tbl$beta,gamma=suav_inputs_tbl$gamma) ##Grilla de Valores
####Se crean las ventanas de rolling y se obtiene los h-pronósticos para cada ventana(hay ntest posibles ventanas)
Errores <- matrix(NA,1000,3)
k=1
for (j in 1:1000) {
alpha=grilla_suav[j,1]
beta=grilla_suav[j,2]
gamma=grilla_suav[j,3]
for(i in 1:(ntest))
{
x=window(lAirPass,end=time(lAirPass)[ntrain]+(i-1)/12)
refit=stats::HoltWinters(x,seasonal="additive",alpha=alpha,beta=beta,gamma=gamma)
fchstepahe[i,]=as.numeric(forecast::forecast(refit,h=h)$mean)
}
#fchstepahe
errores_pred=verval - fchstepahe ##Observación: debo devolver los pronósticos y los verdaderos valores a la escala original si es necesario.
#ECM=apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE) ##Acá se computa la medida de precisión del pronóstico(en este caso ECM).
#RECM=sqrt(ECM) ##Se le saca raíz
#RECM ##se lee: Primera fila RECM 1-paso adelante y así sucesivamente.
Errores[k,]<- sqrt(apply(errores_pred^2,MARGIN = 2,mean,na.rm=TRUE))
k=k+1
}
Errores_df <-as.data.frame(Errores)
colnames(Errores_df)<-c("Paso 1","Paso 2","Paso 3")
min(Errores_df$`Paso 1`)
which.min(Errores_df$`Paso 1`)
which.min(Errores_df$`Paso 2`)
which.min(Errores_df$`Paso 3`)
which()
Errores_df[511,]
Errores_df[411,]
grilla_suav[411,]
grilla_suav[511,]
which.min(apply(Errores, 1, mean))
library(readxl)
datos_1 <- read_excel("~/Documents/Documentos - iMac de Sergio/Documentos iMac Sergio/Cursos/Estadistica para Geografos_2/Quices/Quiz3/datos_1.xlsx")
View(datos_1)
library(readxl)
datos_2 <- read_excel("~/Documents/Documentos - iMac de Sergio/Documentos iMac Sergio/Cursos/Estadistica para Geografos_2/Quices/Quiz3/datos_2.xlsx")
View(datos_2)
hist(datos_1$Gasto)
hist(datos_1$Ingreso)
hist(datos_1$Gasto)
hist(datos_1$Ingreso)
?median
hist(datos_1$Gasto)
hist(datos_1$Ingreso)
mean(datos_1$Gasto)
mean(datos_1$Ingreso)
median(datos_1$Gasto)
median(datos_1$Ingreso)
sd(datos_1$Gasto)
sd(datos_1$Ingreso)
plot(datos_1$Ingreso,datos_1$Gasto)
cor(datos_1$Ingreso,datos_1$Gasto)
hist(datos_2$Gasto)
hist(datos_2$Ingreso)
mean(datos_2$Gasto)
mean(datos_2$Ingreso)
median(datos_2$Gasto)
median(datos_2$Ingreso)
sd(datos_2$Gasto)
sd(datos_2$Ingreso)
plot(datos_2$Ingreso,datos_2$Gasto)
cor(datos_2$Ingreso,datos_2$Gasto)
